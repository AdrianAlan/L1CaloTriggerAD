{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchamark CICADA performance versus supervised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy.linalg import norm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup globals\n",
    "\n",
    "MODELS_DIRECTORY = './models'\n",
    "TRAINING = False\n",
    "CV = 3\n",
    "ZERO_BIAS_DATASET = '/eos/user/a/adpol/L1AD/Background/EphemeralZeroBias2018RunD_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $0.5$~M ZeroBias samples as background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(ZERO_BIAS_DATASET, 'r') as h5:\n",
    "    ZeroBias = h5['CaloRegions'][:500000].astype('float32')\n",
    "print('ZeroBias shape: {}'.format(ZeroBias.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up to $0.5$~M signal samples from each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/eos/user/a/adpol/L1AD/Signal/120X/GluGluHToTauTau_M-125_TuneCP5_14TeV.h5', 'r') as h5:\n",
    "    GluGluHToTauTau = h5['CaloRegions'][:500000].astype('float32')\n",
    "print('GluGluHToTauTau shape: {}'.format(GluGluHToTauTau.shape))\n",
    "\n",
    "with h5py.File('/eos/user/a/adpol/L1AD/Signal/120X/GluGluToHHTo4B_node_cHHH1_TuneCP5_14TeV.h5', 'r') as h5:\n",
    "    GluGluToHHTo4B = h5['CaloRegions'][:500000].astype('float32')\n",
    "print('GluGluToHHTo4B shape: {}'.format(GluGluToHHTo4B.shape))\n",
    "\n",
    "with h5py.File('/eos/user/a/adpol/L1AD/Signal/120X/TT_TuneCP5_14TeV.h5', 'r') as h5:\n",
    "    TTBar = h5['CaloRegions'][:500000].astype('float32')\n",
    "print('TTBar shape: {}'.format(TTBar.shape))\n",
    "\n",
    "with h5py.File('/eos/user/a/adpol/L1AD/Signal/120X/haa4b_ma15_powheg.h5', 'r') as h5:\n",
    "    Haa4b = h5['CaloRegions'][:500000].astype('float32')\n",
    "print('Haa4b shape: {}'.format(Haa4b.shape))\n",
    "\n",
    "with h5py.File('/eos/user/a/adpol/L1AD/Signal/120X/SUEP_L1_NOPU.h5', 'r') as h5:\n",
    "    SUEP = h5['CaloRegions'][:500000].astype('float32')\n",
    "    # Overlay SUEP samples with ZeroBias for pileup\n",
    "    randomevent = np.random.randint(low=0, high=500000, size=500000)\n",
    "    SUEP += ZeroBias[randomevent][:SUEP.shape[0]]\n",
    "print('SUEP shape: {}'.format(SUEP.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate synthetic samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(size, length=3, sigma=0.5, min_pu=20, max_pu=100):\n",
    "    pu = np.random.uniform(min_pu, max_pu, size=size)\n",
    "    eta = np.random.randint(0, 14-length+1, size=size)\n",
    "    phi = np.random.randint(0, 18-length+1, size=size)\n",
    "    ax = np.linspace(-(length - 1) / 2., (length - 1) / 2., length)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sigma))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    regions = np.zeros((size, 18, 14))\n",
    "    for s,(e,p,k) in enumerate(zip(eta, phi, np.repeat(pu, 9).reshape(-1,3,3) * kernel / np.max(kernel))):\n",
    "        regions[s,p:p+3, e:e+3] = k\n",
    "    return regions\n",
    "\n",
    "synthetic = gaussian_kernel(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_deposits(m):\n",
    "    fig, ax = plt.subplots(figsize=(16, 12))\n",
    "    im = ax.imshow(m)\n",
    "    ax.set_ylabel(r'$\\phi$', color='black', size=20)\n",
    "    ax.set_xlabel(r'$\\eta$', color='black', size=20)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    clb = fig.colorbar(im)\n",
    "    clb.ax.tick_params(labelsize=20) \n",
    "    clb.ax.set_title(r'$E_T$',fontsize=20)\n",
    "    plt.title(\"Region deposits\", size=20)\n",
    "    plt.show(fig)\n",
    "    \n",
    "plot_deposits(synthetic[0])\n",
    "plot_deposits(synthetic[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the datasets for fixed size training size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=40000 # upper-bound of SUEP samples\n",
    "\n",
    "ZeroBias_train, ZeroBias_test = train_test_split(\n",
    "    ZeroBias, train_size=train_size, random_state=42, shuffle=True)\n",
    "\n",
    "GluGluHToTauTau_train, GluGluHToTauTau_test = train_test_split(\n",
    "    GluGluHToTauTau, train_size=train_size, random_state=42, shuffle=True)\n",
    "\n",
    "GluGluToHHTo4B_train, GluGluToHHTo4B_test = train_test_split(\n",
    "    GluGluToHHTo4B, train_size=train_size, random_state=42, shuffle=True)\n",
    "\n",
    "TTBar_train, TTBar_test = train_test_split(\n",
    "    TTBar, train_size=train_size, random_state=42, shuffle=True)\n",
    "\n",
    "Haa4b_train, Haa4b_test = train_test_split(\n",
    "    Haa4b, train_size=train_size, random_state=42, shuffle=True)\n",
    "\n",
    "SUEP_train, SUEP_test = train_test_split(\n",
    "    SUEP, train_size=train_size, random_state=42, shuffle=True)\n",
    "\n",
    "synthetic_train, synthetic_test  = train_test_split(\n",
    "    synthetic, train_size=train_size, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a blend of signals for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_train = np.vstack([\n",
    "    GluGluHToTauTau_train[:8000],\n",
    "    GluGluToHHTo4B_train[:8000],\n",
    "    TTBar_train[:8000],\n",
    "    Haa4b_train[:8000],\n",
    "    SUEP_train[:8000]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the supervised models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model that has similar size to the CICADA.v2 student. The only difference is 2 unit output with softmax activation. The softmax does not have to be implemented in hardware so the total FPGA resource usage and latency will be very simialar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Conv2D(filters=3, kernel_size=(3, 3), strides=2, padding='valid', activation='relu', input_shape=(18,14,1)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(units=20, activation='relu'),\n",
    "            layers.Dense(units=2, activation = 'softmax')\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training uses three callbacks: early stopping, reduce on plateu and model checkpointing. Batch size, validation split and learning rate is fixed across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, X, y, batch_size, loss, name, validation_split=0.0, metrics=None):\n",
    "    \n",
    "    early_stopper = EarlyStopping(monitor=\"val_loss\",\n",
    "                                  patience=64,\n",
    "                                  verbose=True,\n",
    "                                  mode=\"auto\")\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor=0.7,\n",
    "                                  patience=5)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint((\"%s/%s.h5\" % (MODELS_DIRECTORY, name)),\n",
    "                                          monitor=\"val_loss\",\n",
    "                                          verbose=False,\n",
    "                                          save_weights_only=False,\n",
    "                                          save_best_only=True,\n",
    "                                          mode=\"min\")\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001,\n",
    "                                beta_1=0.9,\n",
    "                                beta_2=0.999,\n",
    "                                epsilon=None,\n",
    "                                decay=0.0,\n",
    "                                amsgrad=False)\n",
    "\n",
    "    model.compile(loss=loss, metrics=metrics, optimizer=opt)\n",
    "\n",
    "    return model.fit(X, y,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=8192,\n",
    "                     verbose=0,\n",
    "                     initial_epoch=0,\n",
    "                     shuffle=True,\n",
    "                     validation_split=validation_split,\n",
    "                     callbacks=[early_stopper, reduce_lr, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper function to plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(training):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(\"Epoch\", horizontalalignment='right', x=1.0)\n",
    "    ax1.set_ylabel(\"Loss\", horizontalalignment='right', y=1.0)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.tick_params(axis='y', labelcolor='red')\n",
    "    ax1.plot(training.history['loss'],\n",
    "             label='Training')\n",
    "    ax1.plot(training.history['val_loss'],\n",
    "             label='Validation')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Accuracy', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    ax2.plot(training.history['val_accuracy'],\n",
    "             color='green',\n",
    "             label='Val Accuracy')\n",
    "    ax1.legend(bbox_to_anchor=(1.1, 1.00), loc='upper left')\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 0.00), loc='lower left')\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the supervised model and save them to directory. The blend model has an issue with generalization. It will likely have to have either more capacity, experience or both to understand difference between the background and low-PT (and high-PT) signal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_training(signal, name):\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    X_train = np.expand_dims(np.append(ZeroBias_train, signal, axis=0), axis=-1)\n",
    "    y_train = np.append(np.zeros(len(ZeroBias_train)), np.ones(len(signal)), axis=0)\n",
    "    y_train = keras.utils.to_categorical(y_train, 2)\n",
    "\n",
    "    training = train_nn(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        2048,\n",
    "        \"categorical_crossentropy\",\n",
    "        name,\n",
    "        validation_split=0.2,\n",
    "        metrics=\"accuracy\")\n",
    "\n",
    "    plot_loss(training)\n",
    "\n",
    "if TRAINING:\n",
    "    for i in range(CV):\n",
    "        supervised_training(GluGluHToTauTau_train, \"m_GluGluHToTauTau-{}\".format(i))\n",
    "        supervised_training(GluGluToHHTo4B_train, \"m_GluGluToHHTo4B-{}\".format(i))\n",
    "        supervised_training(TTBar_train, \"m_TTBar-{}\".format(i))\n",
    "        supervised_training(Haa4b_train, \"m_Haa4b-{}\".format(i))\n",
    "        supervised_training(SUEP_train, \"m_SUEP-{}\".format(i))\n",
    "        supervised_training(blend_train, \"m_blend-{}\".format(i))\n",
    "        supervised_training(synthetic_train, \"m_synthetic-{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CICADA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cicada_v1 = models.load_model('./ML_CMSL1CaloTrigger/saved_models/model_sA')\n",
    "cicada_v2 = models.load_model('./ML_CMSL1CaloTrigger/saved_models/qmodel_oct24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four metrics to collect: ROC AUC, efficiency at 5kHz, efficiency at 3 kHz, efficiency at 1 kHz. Each model is evaluated on all test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [r\"$\\mathcal{M}_{H \\rightarrow \\tau \\tau}$\",\n",
    "          r\"$\\mathcal{M}_{\\rm{SM }~HH \\rightarrow 4b}$\",\n",
    "          r\"$\\mathcal{M}_{T{\\bar{T}}}$\",\n",
    "          r\"$\\mathcal{M}_{H \\rightarrow aa \\rightarrow 4b}$\",\n",
    "          r\"$\\mathcal{M}_{\\rm{SUEP}}$\",\n",
    "          r\"$\\mathcal{M}_{\\rm{BLEND}}$\",\n",
    "          r\"$\\mathcal{M}_{\\rm{Synthetic}}$\",\n",
    "          r\"$\\mathcal{M}_{\\rm{Baseline}}$\",\n",
    "          r\"$\\mathcal{M}_{\\rm{CICADA.v1}}$\",\n",
    "          r\"$\\mathcal{M}_{\\rm{CICADA.v2}}$\"]\n",
    "datasets = [r\"$\\mathcal{D}_{H \\rightarrow \\tau \\tau}$\",\n",
    "            r\"$\\mathcal{D}_{\\rm{SM }~HH \\rightarrow 4b}$\",\n",
    "            r\"$\\mathcal{D}_{T{\\bar{T}}}$\",\n",
    "            r\"$\\mathcal{D}_{H \\rightarrow aa \\rightarrow 4b}$\",\n",
    "            r\"$\\mathcal{D}_{\\rm{SUEP}}$\",\n",
    "            r\"$\\mathcal{D}_{\\rm{Synthetic}}$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_auc = np.zeros((6, 10))\n",
    "matrix_eff_5hz = np.zeros((6, 10))\n",
    "matrix_eff_3hz = np.zeros((6, 10))\n",
    "matrix_eff_1hz = np.zeros((6, 10))\n",
    "\n",
    "matrix_auc_std = np.zeros((6, 10))\n",
    "matrix_eff_5hz_std = np.zeros((6, 10))\n",
    "matrix_eff_3hz_std = np.zeros((6, 10))\n",
    "matrix_eff_1hz_std = np.zeros((6, 10))\n",
    "\n",
    "for x_idx, signal in enumerate(\n",
    "    [GluGluHToTauTau_test,\n",
    "     GluGluToHHTo4B_test,\n",
    "     TTBar_test,\n",
    "     Haa4b_test,\n",
    "     SUEP_test,\n",
    "     synthetic_test]):\n",
    "\n",
    "    X_test = np.expand_dims(np.append(ZeroBias_test, signal, axis=0), axis=-1)\n",
    "    y_test = np.append(np.zeros(len(ZeroBias_test)), np.ones(len(signal)), axis=0)\n",
    "\n",
    "    for y_idx, name in enumerate(\n",
    "        [\"m_GluGluHToTauTau\",\n",
    "         \"m_GluGluToHHTo4B\",\n",
    "         \"m_TTBar\",\n",
    "         \"m_Haa4b\",\n",
    "         \"m_SUEP\",\n",
    "         \"m_blend\",\n",
    "         \"m_synthetic\"]):\n",
    "\n",
    "        roc_auc, eff5hz, eff3hz, eff1hz = [], [], [], []\n",
    "        for i in range(CV):\n",
    "            model = get_model()\n",
    "            model.load_weights(\"{}/{}-{}.h5\".format(MODELS_DIRECTORY, name, i))\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_test, model.predict(X_test)[:,-1])\n",
    "\n",
    "            roc_auc.append(auc(fpr, tpr))\n",
    "            interpolated = interpolate.interp1d(fpr*28.61, tpr)\n",
    "            eff5hz.append(interpolated(0.005))\n",
    "            eff3hz.append(interpolated(0.003))\n",
    "            eff1hz.append(interpolated(0.001))\n",
    "        \n",
    "        matrix_auc[x_idx][y_idx] = np.mean(roc_auc)\n",
    "        matrix_auc_std[x_idx][y_idx] = np.std(roc_auc)\n",
    "        matrix_eff_5hz[x_idx][y_idx] = np.mean(eff5hz)\n",
    "        matrix_eff_5hz_std[x_idx][y_idx] = np.std(eff5hz)\n",
    "        matrix_eff_3hz[x_idx][y_idx] = np.mean(eff3hz)\n",
    "        matrix_eff_3hz_std[x_idx][y_idx] = np.std(eff3hz)\n",
    "        matrix_eff_1hz[x_idx][y_idx] = np.mean(eff1hz)\n",
    "        matrix_eff_1hz_std[x_idx][y_idx] = np.std(eff1hz)\n",
    "\n",
    "    # Add baseline\n",
    "    pileup = np.mean(ZeroBias_train, axis=0)\n",
    "    fnorm = norm(X_test-pileup.reshape(18, 14, 1), ord=None, axis=(1,2), keepdims=False)\n",
    "    fpr, tpr, _ = roc_curve(y_test, fnorm)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    interpolated = interpolate.interp1d(fpr*28.61, tpr)\n",
    "    eff5hz = interpolated(0.005)\n",
    "    eff3hz = interpolated(0.003)\n",
    "    eff1hz = interpolated(0.001)\n",
    "    matrix_auc[x_idx][7] = roc_auc\n",
    "    matrix_eff_5hz[x_idx][7] = eff5hz\n",
    "    matrix_eff_3hz[x_idx][7] = eff3hz\n",
    "    matrix_eff_1hz[x_idx][7] = eff1hz\n",
    "\n",
    "    # Add CICADA_V1\n",
    "    score = cicada_v1.predict(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    interpolated = interpolate.interp1d(fpr*28.61, tpr)\n",
    "    eff5hz = interpolated(0.005)\n",
    "    eff3hz = interpolated(0.003)\n",
    "    eff1hz = interpolated(0.001)\n",
    "    matrix_auc[x_idx][8] = roc_auc\n",
    "    matrix_eff_5hz[x_idx][8] = eff5hz\n",
    "    matrix_eff_3hz[x_idx][8] = eff3hz\n",
    "    matrix_eff_1hz[x_idx][8] = eff1hz\n",
    "\n",
    "    # Add CICADA_V2\n",
    "    score = cicada_v2.predict(X_test.reshape(-1, 252))\n",
    "    fpr, tpr, _ = roc_curve(y_test, score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    interpolated = interpolate.interp1d(fpr*28.61, tpr)\n",
    "    eff5hz = interpolated(0.005)\n",
    "    eff3hz = interpolated(0.003)\n",
    "    eff1hz = interpolated(0.001)\n",
    "    matrix_auc[x_idx][9] = roc_auc\n",
    "    matrix_eff_5hz[x_idx][9] = eff5hz\n",
    "    matrix_eff_3hz[x_idx][9] = eff3hz\n",
    "    matrix_eff_1hz[x_idx][9] = eff1hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(matrix, matrix_std, title):\n",
    "    fig, ax = plt.subplots(figsize=(16, 12))\n",
    "    im = ax.imshow(matrix, alpha=0.7, cmap='RdYlGn', vmin=np.min(matrix), vmax=np.max(matrix))\n",
    "    # Show all ticks and label them with the respective list entries\n",
    "    ax.set_xticks(np.arange(len(models)), labels=models)\n",
    "    ax.set_yticks(np.arange(len(datasets)), labels=datasets)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(datasets)):\n",
    "        for j in range(len(models)):\n",
    "            if j < 7:\n",
    "                text = ax.text(j, i,\n",
    "                               \"\"\"{0:.4f}\n",
    "\n",
    "$\\pm$ {1:.4f}\"\"\".format(matrix[i, j], matrix_std[i, j]),\n",
    "                               ha=\"center\", va=\"center\", color=\"black\", size=14)\n",
    "            else:\n",
    "                text = ax.text(j, i, \"{0:.4f}\".format(matrix[i, j]),\n",
    "                               ha=\"center\", va=\"center\", color=\"black\", size=14)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(matrix_auc, matrix_auc_std, \"ROC AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(matrix_eff_5hz, matrix_eff_5hz_std, \"Efficiency 5kHz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(matrix_eff_3hz, matrix_eff_3hz_std, \"Efficiency 3kHz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(matrix_eff_1hz, matrix_eff_1hz_std, \"Efficiency 1kHz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
