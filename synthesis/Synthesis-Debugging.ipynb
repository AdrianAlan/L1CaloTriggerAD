{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Config and Complie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './ML_CMSL1CaloTrigger/saved_models/qmodel_oct24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/work/a/adpol/l1calotriggerad/synthesis/hls4ml/converters/__init__.py:24: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import hls4ml\n",
    "\n",
    "from qkeras import *\n",
    "from qkeras.utils import load_qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 12:09:09.248034: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-02-09 12:09:09.248128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lxplus703.cern.ch): /proc/driver/nvidia/version does not exist\n",
      "2023-02-09 12:09:09.412784: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,4,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,2,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,2,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,2,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Looks like there is an object (perhaps variable or layer) that is shared between different layers/models. This may cause issues when restoring the variable values. Object: quantized_bits(16,2,1,alpha='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 2} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 2} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 9} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 9} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 2, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 15} and quantized_bits(16,2,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 2, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 15} and quantized_bits(16,2,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 2} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 2} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 9} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 4, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 9} and quantized_bits(16,4,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 2, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 15} and quantized_bits(16,2,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects ({'class_name': 'quantized_bits', 'config': DictWrapper({'bits': 16, 'integer': 2, 'symmetric': True, 'alpha': 'auto', 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}), 'shared_object_id': 15} and quantized_bits(16,2,1,alpha='auto')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "In (InputLayer)              [(None, 252)]             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 18, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv (QConv2D)               (None, 8, 6, 3)           27        \n",
      "_________________________________________________________________\n",
      "relu1 (QActivation)          (None, 8, 6, 3)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense1 (QDense)              (None, 20)                2880      \n",
      "_________________________________________________________________\n",
      "relu2 (QActivation)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (QDense)              (None, 1)                 20        \n",
      "=================================================================\n",
      "Total params: 2,927\n",
      "Trainable params: 2,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_qmodel(MODEL_DIR);\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: In, layer type: InputLayer, input shapes: [[None, 252]], output shape: [None, 252]\n",
      "Layer name: reshape, layer type: Reshape, input shapes: [[None, 252]], output shape: [None, 18, 14, 1]\n",
      "Layer name: conv, layer type: QConv2D, input shapes: [[None, 18, 14, 1]], output shape: [None, 8, 6, 3]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 8, 6, 3]], output shape: [None, 8, 6, 3]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 8, 6, 3]], output shape: [None, 144]\n",
      "Layer name: dense1, layer type: QDense, input shapes: [[None, 144]], output shape: [None, 20]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 20]], output shape: [None, 20]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 20]], output shape: [None, 1]\n"
     ]
    }
   ],
   "source": [
    "hls4ml.model.optimizer.get_optimizer(\n",
    "    'output_rounding_saturation_mode'\n",
    ").configure(\n",
    "    layers=['relu1', 'relu2'],\n",
    "    rounding_mode='AP_RND',\n",
    "    saturation_mode='AP_SAT',\n",
    "    saturation_bits='AP_SAT'\n",
    ")\n",
    "hls4ml.model.optimizer.get_optimizer(\n",
    "    'eliminate_linear_activation'\n",
    ")\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(\n",
    "    model,\n",
    "    granularity='name'\n",
    ")\n",
    "\n",
    "hls_config['Model']['ReuseFactor'] = 4\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "hls_config['Model']['ClockPeriod']  = 6.25\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16, 6>'\n",
    "# hls_config['Model']['Trace']  = True\n",
    "\n",
    "for layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][layer]['Strategy'] = 'Resource'\n",
    "    hls_config['LayerName'][layer]['ReuseFactor'] = 4\n",
    "    # hls_config['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "hls_config['LayerName']['In']['Precision']['accum'] = 'ap_ufixed<10, 10>'\n",
    "hls_config['LayerName']['In']['Precision']['result'] = 'ap_ufixed<10, 10>'\n",
    "\n",
    "hls_config['LayerName']['conv']['Precision']['accum'] = 'ap_fixed<20, 8>'\n",
    "hls_config['LayerName']['conv']['Precision']['result'] = 'ap_fixed<20, 8>'\n",
    "hls_config['LayerName']['conv_linear']['Precision'] = 'ap_fixed<20, 8>'\n",
    "hls_config['LayerName']['conv']['Strategy'] = 'Resource'\n",
    "hls_config['LayerName']['conv']['ReuseFactor'] = 1\n",
    "hls_config['LayerName']['conv']['ParallelizationFactor'] = 12\n",
    "\n",
    "hls_config['LayerName']['dense1']['Precision']['accum'] = 'ap_fixed<22, 8>'\n",
    "hls_config['LayerName']['dense1']['Precision']['result'] = 'ap_fixed<22, 8>'\n",
    "hls_config['LayerName']['dense1_linear']['Precision'] = 'ap_fixed<22, 8>'\n",
    "hls_config['LayerName']['dense1']['Strategy'] = 'Latency'\n",
    "\n",
    "hls_config['LayerName']['output']['Precision']['accum'] = 'ap_fixed<16, 8>'\n",
    "hls_config['LayerName']['output']['Precision']['result'] = 'ap_ufixed<16, 8>'\n",
    "hls_config['LayerName']['output_linear']['Precision'] = 'ap_ufixed<16, 8>'\n",
    "\n",
    "cfg = hls4ml.converters.create_config(part=\"xc7vx690tffg1927-2\")\n",
    "\n",
    "cfg['IOType'] = 'io_parallel'\n",
    "cfg['HLSConfig'] = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['ClockPeriod']  = 6.25\n",
    "cfg['OutputDir']  = 'cicada/'\n",
    "cfg['Part'] = 'xc7vx690tffg1927-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: In, layer type: InputLayer, input shapes: [[None, 252]], output shape: [None, 252]\n",
      "Layer name: reshape, layer type: Reshape, input shapes: [[None, 252]], output shape: [None, 18, 14, 1]\n",
      "Layer name: conv, layer type: QConv2D, input shapes: [[None, 18, 14, 1]], output shape: [None, 8, 6, 3]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 8, 6, 3]], output shape: [None, 8, 6, 3]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 8, 6, 3]], output shape: [None, 144]\n",
      "Layer name: dense1, layer type: QDense, input shapes: [[None, 144]], output shape: [None, 20]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 20]], output shape: [None, 20]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 20]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "\n",
    "hls4ml.model.optimizer.get_optimizer(\n",
    "    'output_rounding_saturation_mode'\n",
    ").configure(layers=[])\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=False, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.model.profiling.numerical(model=model, hls_model=hls_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCEPTED_ERROR = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test vector, zeros:\n",
    "tv_0 = np.zeros((1, 252)) + 0.\n",
    "\n",
    "# Test vector, ones:\n",
    "tv_1 = np.zeros((1, 252)) + 1.\n",
    "\n",
    "# Test vector, mean zero bias, 2018 run D:\n",
    "tv_zb = np.array([[2, 1, 1, 2, 1, 2, 3, 3, 3, 2, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 2, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 1, 2, 2, 3, 3, 2, 2, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 1, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 4, 3, 2, 4, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 2, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 3, 2, 3, 5, 2, 2, 1, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 3, 4, 3, 2, 2, 2, 1, 1, 3],\n",
    "       [2, 1, 1, 2, 2, 3, 4, 3, 2, 1, 2, 1, 1, 3],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [0, 0, 0, 2, 2, 2, 3, 3, 2, 2, 2, 1, 1, 2],\n",
    "       [0, 0, 0, 3, 2, 3, 5, 4, 3, 2, 4, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 4, 3, 2, 2, 4, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 3, 1, 1, 2]]).reshape(1, 252) + 0.\n",
    "\n",
    "# Test vector, signal haa4b_ma15_powheg average:\n",
    "tv_sig = np.array([[8, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 8],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 9],\n",
    "       [9, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 9],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 9],\n",
    "       [8, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 8],\n",
    "       [8, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 8],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 9],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 9],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 8],\n",
    "       [8, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 8],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 8],\n",
    "       [9, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 9],\n",
    "       [9, 2, 2, 3, 2, 3, 3, 3, 3, 2, 3, 2, 2, 9],\n",
    "       [8, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 8],\n",
    "       [8, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 8],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 9],\n",
    "       [9, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 9],\n",
    "       [8, 2, 2, 3, 2, 3, 3, 3, 3, 2, 3, 2, 2, 8]]).reshape(1, 252) + 0.\n",
    "\n",
    "# Test vector, hand made:\n",
    "tv_hand = np.array([[2, 1, 1, 2, 1, 2, 3, 3, 3, 2, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 2, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 1, 2, 2, 1023, 3, 2, 2, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 1, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 1023, 1023, 2, 3, 4, 3, 2, 4, 1023, 1, 2],\n",
    "       [2, 1, 1023, 1023, 2, 2, 3, 3, 2, 2, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 3, 2, 3, 5, 2, 2, 1, 3, 1023, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 3, 4, 3, 2, 2, 2, 1, 1, 3],\n",
    "       [2, 1, 1, 2, 2, 3, 4, 3, 2, 1, 2, 1, 1, 3],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 1023, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 1023, 2, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 3, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 1023, 2, 3, 3, 2, 1, 2, 1, 1, 2],\n",
    "       [0, 1023, 0, 2, 2, 2, 3, 3, 2, 2, 2, 1, 1, 2],\n",
    "       [0, 0, 0, 3, 2, 3, 5, 4, 3, 2, 4, 1, 1, 2],\n",
    "       [2, 1, 1, 2, 2, 2, 4, 3, 2, 2, 1023, 1, 1, 2],\n",
    "       [2, 1023, 1, 2, 2, 2, 3, 3, 2, 1, 3, 1, 1, 2]]).reshape(1, 252) + 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tv in [tv_0, tv_1, tv_zb, tv_sig, tv_hand]:\n",
    "    print(abs(model.predict(tv) - hls_model.predict(tv)) <= ACCEPTED_ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real signal samples\n",
    "\n",
    "scores = []\n",
    "errors = []\n",
    "\n",
    "for dataset in [\n",
    "    '/eos/user/a/adpol/L1AD/Signal/120X/haa4taus_ma15_powheg.h5',\n",
    "    '/eos/user/a/adpol/L1AD/Signal/120X/haa4b_ma50_powheg.h5',\n",
    "    '/eos/user/a/adpol/L1AD/Signal/120X/emj-mMed-800-mDark-10-ctau-1000.h5']:\n",
    "    X_test = h5py.File(dataset,'r')['CaloRegions']\n",
    "    for idx in range(min(4000, len(X_test))):\n",
    "        vector = X_test[idx].reshape(1, 252) + 0.\n",
    "        score_keras = float(model.predict(vector))\n",
    "        score_hls4ml = hls_model.predict(vector)\n",
    "        diff = abs(score_keras - score_hls4ml)\n",
    "        if diff > ACCEPTED_ERROR:\n",
    "            print('Error', diff)\n",
    "        errors.append(diff)\n",
    "        scores.append(score_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(scores, errors, s=1)\n",
    "plt.xlabel('Anomaly Score, $S$', fontsize=18)\n",
    "plt.ylabel('Error, $|S_{Keras} - S_{hls4ml}|$', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(tv_0), hls_model.predict(tv_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml_pred, hls4ml_trace = hls_model.trace(tv_0)\n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, tv_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the uncertainty in tcl: set_clock_uncertainty 30% {get_clocks default}\n",
    "\n",
    "!grep -n create_clock cicada/build_prj.tcl | awk -F \":\" '{print$1}' | ( read line; echo \"$((line + 1)) \") | xargs -I {} sed -i '{} i set_clock_uncertainty 30% {get_clocks default}' cicada/build_prj.tcl \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Vivado HLS\n",
    "\n",
    "!vivado_hls -f cicada/build_prj.tcl \"reset=1 synth=1 csim=0 cosim=0 validation=0 export=0 vsynth=0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the report\n",
    "\n",
    "!cat cicada/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
